{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Parameters\n",
    "\n",
    "The purpose of this notebook is to find the best parameters for the different sets of features. In order to do so, a model needs to be selected, along with the parameter space that will be searched. First a coarse grid search is performed, and then a more narrow one. The result of a notebook end to end run, should be a csv file with a specified name that mentions the model it is for. The csv for an SVM for example should look like:\n",
    "\n",
    "    parameter, value  <-- (header)\n",
    "    kernel, rbf\n",
    "    nu, 0.01\n",
    "    degree, 3\n",
    "    gamma, 0.05\n",
    "    coef0, 0.0\n",
    "    \n",
    "In order to successfully run the notebook for its purpose, the sections that need to be modified for a new algorithm are:\n",
    "\n",
    "    1. Model Selection (where a new model is initialized)\n",
    "    2. Parameter Space - Coarse (where the selected parameters need to correspond to the algorithm)\n",
    "    3. Drop a cleaner csv with only the best parameters (where the parameter names need to be set\n",
    "       accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files selected from the directory is 16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "from time import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "rows_each = 60\n",
    "\n",
    "# specify the place from where we will use the data\n",
    "source_path_rel = 'data/Main collection - features/'\n",
    "\n",
    "# specify the target path for dropping the parameters\n",
    "target_path_rel = 'data/Main collection - results/parameters/'\n",
    "\n",
    "# find the file names in the directory\n",
    "feature_files = os.listdir(source_path_rel)\n",
    "\n",
    "# remove the readme, and the Giorgos files\n",
    "feature_files.remove('README.md')\n",
    "feature_files.remove('Giorgos Mon 19.csv')\n",
    "feature_files.remove('Giorgos Wed 21.csv')\n",
    "feature_files.remove('Giorgos Fri 23.csv')\n",
    "feature_files.remove('Giorgos Mon 26.csv')\n",
    "feature_files.remove('best ratios by multiclass RF')\n",
    "\n",
    "print(\"The number of files selected from the directory is {}\".format(len(feature_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING OPTIONS\n",
    "np.set_printoptions(threshold=80)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all data in a single DataFrame\n",
    "\n",
    "The process here is to sample 60 locks from each participant. Some participants have more than 60 locks and in that case we select the lokcs randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe that holds the data is as follows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB_mil</th>\n",
       "      <th>AB_xyz</th>\n",
       "      <th>AB|AC_mil</th>\n",
       "      <th>AB|AC_xyz</th>\n",
       "      <th>...</th>\n",
       "      <th>zSpeed_range</th>\n",
       "      <th>zSpeed_skew</th>\n",
       "      <th>zSpeed_std</th>\n",
       "      <th>zSpeed_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434.0</td>\n",
       "      <td>258.930923</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.655369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081136</td>\n",
       "      <td>-0.149765</td>\n",
       "      <td>0.184878</td>\n",
       "      <td>0.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502.0</td>\n",
       "      <td>297.418459</td>\n",
       "      <td>0.548035</td>\n",
       "      <td>0.629426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088235</td>\n",
       "      <td>1.069284</td>\n",
       "      <td>0.282818</td>\n",
       "      <td>0.079986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529.0</td>\n",
       "      <td>339.767000</td>\n",
       "      <td>0.549325</td>\n",
       "      <td>0.757873</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.249953</td>\n",
       "      <td>0.062477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503.0</td>\n",
       "      <td>301.571361</td>\n",
       "      <td>0.558269</td>\n",
       "      <td>0.689733</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217469</td>\n",
       "      <td>1.207258</td>\n",
       "      <td>0.290968</td>\n",
       "      <td>0.084663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>445.0</td>\n",
       "      <td>158.355584</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.820856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.489388</td>\n",
       "      <td>0.124969</td>\n",
       "      <td>0.015617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>436.0</td>\n",
       "      <td>138.876355</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.597251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491597</td>\n",
       "      <td>0.393809</td>\n",
       "      <td>0.109206</td>\n",
       "      <td>0.011926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>495.0</td>\n",
       "      <td>183.983717</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.818607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897829</td>\n",
       "      <td>-0.483202</td>\n",
       "      <td>0.137261</td>\n",
       "      <td>0.018841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>477.0</td>\n",
       "      <td>175.668280</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.857197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.742492</td>\n",
       "      <td>0.105224</td>\n",
       "      <td>0.011072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AB_mil      AB_xyz  AB|AC_mil  AB|AC_xyz     ...      zSpeed_range  \\\n",
       "0     434.0  258.930923   0.418919   0.655369     ...          1.081136   \n",
       "1     502.0  297.418459   0.548035   0.629426     ...          2.088235   \n",
       "2     529.0  339.767000   0.549325   0.757873     ...          1.235294   \n",
       "3     503.0  301.571361   0.558269   0.689733     ...          2.217469   \n",
       "..      ...         ...        ...        ...     ...               ...   \n",
       "956   445.0  158.355584   0.654412   0.820856     ...          0.558824   \n",
       "957   436.0  138.876355   0.586022   0.597251     ...          0.491597   \n",
       "958   495.0  183.983717   0.651316   0.818607     ...          0.897829   \n",
       "959   477.0  175.668280   0.671831   0.857197     ...          0.421429   \n",
       "\n",
       "     zSpeed_skew  zSpeed_std  zSpeed_var  \n",
       "0      -0.149765    0.184878    0.034180  \n",
       "1       1.069284    0.282818    0.079986  \n",
       "2       0.071162    0.249953    0.062477  \n",
       "3       1.207258    0.290968    0.084663  \n",
       "..           ...         ...         ...  \n",
       "956     0.489388    0.124969    0.015617  \n",
       "957     0.393809    0.109206    0.011926  \n",
       "958    -0.483202    0.137261    0.018841  \n",
       "959     0.742492    0.105224    0.011072  \n",
       "\n",
       "[960 rows x 916 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the data frame with the locks that will be used\n",
    "X = pd.DataFrame()\n",
    "\n",
    "for i, file in enumerate(feature_files):\n",
    "    \n",
    "    # read each features file into a df\n",
    "    df = pd.read_csv(source_path_rel+file)\n",
    "    \n",
    "    # select a sample of 60 values (without replacement)\n",
    "    df = df.sample(n=rows_each, random_state=random_state, axis=0)\n",
    "    \n",
    "    # sort the sampled dataframe by index \n",
    "    df.index = range(df.shape[0])\n",
    "    \n",
    "    # add the data to the bigger dataframe\n",
    "    X = pd.concat([X, df.loc[:, :]], ignore_index=True)\n",
    "    \n",
    "print(\"The dataframe that holds the data is as follows:\")\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets selection\n",
    "\n",
    "After loading the data, the next step is to select features. The parameter tuning will be across all the feature groups. There will be 10 groups of features that we will deal with here. These 10 groups of features can be grouped in 3 broader groups which are the overal/holistic features, the distances and the ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRatioFeatureIds(file_name, n=30):\n",
    "    \"\"\" Loads the file with features. \"\"\"\n",
    "    df = pd.read_csv('data/Main collection - features/best ratios by multiclass RF/' + file_name)\n",
    "    return df.loc[:n-1, 'feature id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMagnitudes(f1, f2):\n",
    "    \"\"\" Selects the features for both f1 and f2 lists that start with mag. \"\"\"\n",
    "    ff = [f for f in f1 if f[:3]=='mag']\n",
    "    ff.extend([f for f in f2 if f[:3]=='mag'])\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features\n",
    "all_features = X.columns.values.tolist()\n",
    "\n",
    "# find all positional features\n",
    "pos_features = [f for f in all_features if f[1:4]=='Pos' and f[4]!='I']\n",
    "\n",
    "# find all position intervals\n",
    "posInc_features = [f for f in all_features if f[1:7]=='PosInc' or f[3:9]=='PosInc']\n",
    "\n",
    "# find all speed intervals\n",
    "speed_features = [f for f in all_features if f[1:6]=='Speed' or f[3:8]=='Speed']\\\n",
    "\n",
    "# find all x axis features\n",
    "\n",
    "\n",
    "# find all y axis features\n",
    "\n",
    "\n",
    "# find all z axis features\n",
    "\n",
    "\n",
    "# find all magnitude features\n",
    "#magnitude_features = findMagnitudes(posInc_features, speed_features)\n",
    "\n",
    "# find all euclidean distances\n",
    "euc_dist_features = [f for f in all_features if f[2]=='_' and f[-3:]=='xyz']\n",
    "\n",
    "# find all temporal distances\n",
    "mil_dist_features = [f for f in all_features if f[2]=='_' and f[-3:]=='mil']\n",
    "\n",
    "# combine euc and mil distances\n",
    "\n",
    "\n",
    "# find the selected euclidean ratios\n",
    "euc_ratio_features = loadRatioFeatureIds('Euclidean distance ratios.csv')\n",
    "\n",
    "# find the selected temporal ratios\n",
    "mil_ratio_features = loadRatioFeatureIds('Temporal distance ratios.csv')\n",
    "\n",
    "# find the selected euclidean ratios\n",
    "euc_all_ratio_features = [f for f in all_features if f[2]=='|' and f[-3:]=='xyz']\n",
    "\n",
    "# find the selected temporal ratios\n",
    "mil_all_ratio_features = [f for f in all_features if f[2]=='|' and f[-3:]=='mil']\n",
    "\n",
    "# combine euc and temp ratios\n",
    "\n",
    "\n",
    "# combine ratios and distances\n",
    "\n",
    "\n",
    "# ----- combine best performing ones\n",
    "\n",
    "# best 1 \n",
    "\n",
    "\n",
    "# best 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [pos_features, posInc_features, speed_features, euc_dist_features,\n",
    "                mil_dist_features, euc_ratio_features, mil_ratio_features,\n",
    "                euc_all_ratio_features, mil_all_ratio_features, all_features]\n",
    "\n",
    "feature_set_names = ['positions', 'position intervals', 'speed intervals', 'euclidean distances',\n",
    "                     'temporal distances', 'euclidean ratios', 'temporal ratios',\n",
    "                     'euclidean ratios (all 356)', 'temporal ratios (all 356)', 'all features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "The next step is to initialize the models and make a selection of the one that will be used. Because this notebook is supposed to use only one model, the selected classifier needs to be selected in the next cell by commenting out the remaining options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# selected_classifier = svm.OneClassSVM()\n",
    "# selected_classifier_name = 'one-class SVM'\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "selected_classifier = IsolationForest()\n",
    "selected_classifier_name = 'Isolation Forest'\n",
    "\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "# selected_classifier = EllipticEnvelope()\n",
    "# selected_classifier_name = 'Elliptic Envelope'\n",
    "\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# selected_classifier = LocalOutlierFactor()\n",
    "# selected_classifier_name = 'Local Outlier Factor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Space - Coarse\n",
    "\n",
    "Here for every algorithm that will be probed, we will define the parameter space for a coarse grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for one-class SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = [0.1, 0.3, 0.5, 0.7, 0.9]    # nu\n",
    "degree = [1, 2, 3, 4]             # degree (poly)\n",
    "gamma = [0.1, 0.3, 0.5, 0.7, 0.9] # gamma (rbf, poly sigmoid)\n",
    "coef0 = [0.1, 0.3, 0.5, 0.7, 0.9] # coef0 (poly, sigmoid)\n",
    "\n",
    "def_degree = [3.0]\n",
    "def_gamma = ['auto']\n",
    "def_coef0 = [0.0]\n",
    "\n",
    "# initialize a list of parameters the classifier can take\n",
    "parameters_SVM = [{'kernel': ['linear'],\n",
    "                   'nu': nu,\n",
    "                   'degree': def_degree,\n",
    "                   'gamma': def_gamma,\n",
    "                   'coef0': def_coef0},\n",
    "                  {'kernel': ['rbf'],\n",
    "                   'nu': nu,\n",
    "                   'degree': def_degree,\n",
    "                   'gamma': gamma,\n",
    "                   'coef0': def_coef0},\n",
    "                  {'kernel': ['poly'],\n",
    "                   'nu': nu,\n",
    "                   'degree': degree,\n",
    "                   'gamma': gamma,\n",
    "                   'coef0': coef0},\n",
    "                  {'kernel': ['sigmoid'],\n",
    "                   'nu': nu,\n",
    "                   'degree': def_degree,\n",
    "                   'gamma': gamma,\n",
    "                   'coef0': coef0}]\n",
    "\n",
    "param_names_SVM = ['kernel', 'nu', 'degree', 'gamma', 'coef0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list of parameters the classifier can take\n",
    "parameters_SVM_only_rbf = [{'kernel': ['rbf'],\n",
    "                           'nu': nu,\n",
    "                           'degree': def_degree,\n",
    "                           'gamma': gamma,\n",
    "                           'coef0': def_coef0}]\n",
    "\n",
    "param_names_SVM = ['kernel', 'nu', 'degree', 'gamma', 'coef0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for Isolation Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [300, 400, 500, 600]      # number of estimators\n",
    "contamination = [0.05, 0.2, 0.35] # contamination\n",
    "max_features = [0.5, 0.7, 0.9]    # max features\n",
    "\n",
    "def_samples = [1.0]\n",
    "\n",
    "parameters_IF = [{'n_estimators': estimators,\n",
    "                  'max_samples': def_samples,\n",
    "                  'contamination': contamination,\n",
    "                  'max_features': max_features}]\n",
    "\n",
    "param_names_IF = ['n_estimators', 'max_samples', 'contamination', 'max_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findListOfParameters(parameters):\n",
    "    \"\"\" Returns all combinations by the dictionary values, in a list of dictionaries \"\"\"\n",
    "    return [tup for d in parameters for tup in list(itertools.product(*d.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_parameters = findListOfParameters(parameters_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse Grid Search\n",
    "\n",
    "In order to find the optimal parameter combination, we will run the selected model for every user and every group of features. Then we will select the parameters with the best mean score across all combinations of users with features. The data structure that we will use will look like:\n",
    "\n",
    "|                 | f1,u1 | f1,u2 |  ...  | f1,uN |  ...  | fN,u1 | fN,u2 |  ...  | fN,uN |\n",
    "|-----------------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n",
    "|   parameters1   |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |\n",
    "|   parameters2   |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |\n",
    "|       ...       |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |\n",
    "|   parametersN   |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addParamsToClf(clf, p, clf_name):\n",
    "    \"\"\" Adds the parameters of the classifier according to its name. \"\"\"\n",
    "    \n",
    "    if clf_name == 'one-class SVM':\n",
    "        clf.set_params(kernel=p[0], nu=p[1], degree=p[2], gamma=p[3], coef0=p[4])\n",
    "    elif clf_name == 'Isolation Forest':\n",
    "        clf.set_params(n_estimators=p[0], max_samples=p[1], contamination=p[2], max_features=p[3])\n",
    "    else:\n",
    "        raise ValueError('The classifier name is not enlisted')\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFalseNegatives(pred):\n",
    "    \"\"\" Finds the False Negatives in a prediction of only positive samples. \"\"\"\n",
    "    # get the unique predicted labels and their counts in a dictionary\n",
    "    unique_counts = dict(zip(*np.unique(pred, return_counts=True)))\n",
    "    # find the correct predictions\n",
    "    num_correct_predictions = unique_counts[-1] if -1 in unique_counts else 0\n",
    "    #return the ratio\n",
    "    return num_correct_predictions / sum(unique_counts.values()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFalsePositives(pred):\n",
    "    \"\"\" Finds the False Positives in a prediction of only negative samples. \"\"\"\n",
    "    # get the unique predicted labels and their counts in a dictionary\n",
    "    unique_counts = dict(zip(*np.unique(pred, return_counts=True)))\n",
    "    # find the correct predictions\n",
    "    num_correct_predictions = unique_counts[1] if 1 in unique_counts else 0\n",
    "    #return the ratio\n",
    "    return num_correct_predictions / sum(unique_counts.values()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyWithCV(X_positive, X_negative, clf, scaler, folds=5, random_state=0):\n",
    "    \"\"\" Finds the convergence line of a classifier, in different samples. \"\"\"\n",
    "    \n",
    "    # initialize a cross validation object\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    FN_rates = []\n",
    "\n",
    "    for train, test in kf.split(X_positive):\n",
    "\n",
    "        # fit the scalar\n",
    "        scaler.fit(X_positive.loc[train, :])\n",
    "\n",
    "        # scale all data before fitting the classifier or making predictions\n",
    "        X_pos_transformed_train = scaler.transform(X_positive.loc[train, :])\n",
    "        X_pos_transformed_test = scaler.transform(X_positive.loc[test, :])\n",
    "        \n",
    "        # fit the classifier\n",
    "        clf.fit(X_pos_transformed_train)\n",
    "\n",
    "        # make predictions on Positive data\n",
    "        prediction_pos = clf.predict(X_pos_transformed_test)\n",
    "\n",
    "        # find the false negatives of the split and save to the array\n",
    "        FN_rates.append(findFalseNegatives(prediction_pos))\n",
    "        \n",
    "    # fit the scalar\n",
    "    scaler.fit(X_positive)\n",
    "    X_pos_transformed_train = scaler.transform(X_positive)\n",
    "    X_neg_transformed_test = scaler.transform(X_negative)\n",
    "    \n",
    "    # fit the classifier\n",
    "    clf.fit(X_pos_transformed_train)\n",
    "\n",
    "    # make predictions on Positive data\n",
    "    prediction_neg = clf.predict(X_neg_transformed_test)\n",
    "\n",
    "    # find the false positives\n",
    "    FP_rate = findFalsePositives(prediction_neg)\n",
    "        \n",
    "    # return the mean of the two (more intuitive sense than the sum)\n",
    "    return sum([np.mean(FN_rates), FP_rate])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParameter_GridSearch(X_all, clf, params, features, users, clf_name, search_type,\n",
    "                             locks_per_participant=60):\n",
    "    \"\"\" Finds the best set of parameters across all users and features \"\"\"\n",
    "    \n",
    "    # initialize the dataframe for all values\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # initialize a minmax scalar\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    for cc, p in enumerate(params):\n",
    "        \n",
    "        # add the parameters to the classifier according to its name\n",
    "        classifier = addParamsToClf(selected_classifier, p, selected_classifier_name)\n",
    "        \n",
    "        if clf_name=='one-class SVM':\n",
    "            param_string = '{}, {}, {}, {}, {}'.format(*p)\n",
    "        elif clf_name=='Isolation Forest':\n",
    "            param_string = '{}, {}, {}, {}'.format(*p)\n",
    "        else:\n",
    "            raise ValueError(\"Something is wrong with the classifier name\")\n",
    "        \n",
    "        print(\"Currently working on the {}/{} set of parameters which is: \"\n",
    "              .format(cc+1, len(params))+param_string+\" ...\")\n",
    "        \n",
    "        for i, f in enumerate(features):\n",
    "\n",
    "            for j, u in enumerate(users):\n",
    "                \n",
    "                # define the column name\n",
    "                col = 'f'+str(i+1)+', u'+str(j+1)\n",
    "                \n",
    "                # find the starting index of the original dataframe\n",
    "                idx = j*locks_per_participant\n",
    "        \n",
    "                # find the mask for positive values to slice the dataset\n",
    "                positive_mask = X_all.index.isin(range(idx, idx+locks_per_participant))\n",
    "\n",
    "                # find the lines that correspond to this participant and the feature set\n",
    "                X_pos = X_all.loc[positive_mask, f]\n",
    "\n",
    "                # find the lines that correspond to all other participants and the feature set\n",
    "                X_neg = X_all.loc[~positive_mask, f]\n",
    "\n",
    "                # reset the index of the features dataframe\n",
    "                X_pos.index = range(X_pos.shape[0])\n",
    "                \n",
    "                # reset the index of the features dataframe\n",
    "                X_neg.index = range(X_neg.shape[0])\n",
    "                \n",
    "                # run classify with cv\n",
    "                df.loc[param_string, col] = classifyWithCV(X_pos, X_neg, classifier, scaler)\n",
    "                \n",
    "            # give some feedback that the feature is finished\n",
    "            print('The models are finished for {}/10 features'.format(i+1))\n",
    "            \n",
    "        clear_output()\n",
    "            \n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    # set new column for the parameters\n",
    "    df.loc[:, 'parameters'] = df.index\n",
    "    \n",
    "    # make new column for the mean scores\n",
    "    df.loc[:, 'mean FN+FP'] = np.mean(df.loc[:, cols], axis=1)\n",
    "    \n",
    "    # make new column for the mean scores\n",
    "    df.loc[:, 'std FN+FP'] = np.std(df.loc[:, cols], axis=1)\n",
    "    \n",
    "    # reset the index of the features dataframe\n",
    "    df.index = range(df.shape[0])\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    # reorder the columns\n",
    "    cols = cols[-3:] + cols[:-3]\n",
    "    \n",
    "    df = df[cols]\n",
    "    \n",
    "    print(\"The result of the grid search for the parameters is:\\n\")\n",
    "    \n",
    "    # show the dataframe\n",
    "    display(df)\n",
    "    \n",
    "    # log the results\n",
    "    df.to_csv(target_path_rel + '{} logs for {}.csv'.format(search_type, clf_name), index=False)\n",
    "    \n",
    "    # find the winning line\n",
    "    winning_line = df.loc[df.loc[:, 'mean FN+FP'].idxmin(), :]\n",
    "        \n",
    "    # return the parameter with the smallest sum of mean FN and FP\n",
    "    return winning_line['parameters'], winning_line['mean FN+FP'], winning_line['std FN+FP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected parameter sets are 36.\n"
     ]
    }
   ],
   "source": [
    "print('The selected parameter sets are {}.'. format(len(selected_parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the grid search for the parameters is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean FN+FP</th>\n",
       "      <th>std FN+FP</th>\n",
       "      <th>f1, u1</th>\n",
       "      <th>...</th>\n",
       "      <th>f10, u13</th>\n",
       "      <th>f10, u14</th>\n",
       "      <th>f10, u15</th>\n",
       "      <th>f10, u16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300, 1.0, 0.05, 0.5</td>\n",
       "      <td>23.742014</td>\n",
       "      <td>11.945584</td>\n",
       "      <td>16.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>29.111111</td>\n",
       "      <td>10.222222</td>\n",
       "      <td>9.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300, 1.0, 0.05, 0.7</td>\n",
       "      <td>23.649653</td>\n",
       "      <td>12.194530</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>34.888889</td>\n",
       "      <td>11.055556</td>\n",
       "      <td>17.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300, 1.0, 0.05, 0.9</td>\n",
       "      <td>23.268403</td>\n",
       "      <td>12.029715</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.611111</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300, 1.0, 0.2, 0.5</td>\n",
       "      <td>19.993750</td>\n",
       "      <td>7.076355</td>\n",
       "      <td>19.722222</td>\n",
       "      <td>...</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>12.722222</td>\n",
       "      <td>11.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>600, 1.0, 0.2, 0.9</td>\n",
       "      <td>19.917361</td>\n",
       "      <td>7.384408</td>\n",
       "      <td>19.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>15.222222</td>\n",
       "      <td>17.888889</td>\n",
       "      <td>9.555556</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>600, 1.0, 0.35, 0.5</td>\n",
       "      <td>24.411111</td>\n",
       "      <td>4.147089</td>\n",
       "      <td>19.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>22.222222</td>\n",
       "      <td>22.944444</td>\n",
       "      <td>23.555556</td>\n",
       "      <td>21.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>600, 1.0, 0.35, 0.7</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>4.419286</td>\n",
       "      <td>19.611111</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>23.555556</td>\n",
       "      <td>19.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>600, 1.0, 0.35, 0.9</td>\n",
       "      <td>24.283681</td>\n",
       "      <td>4.158448</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.611111</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>22.722222</td>\n",
       "      <td>22.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             parameters  mean FN+FP  std FN+FP     f1, u1    ...      \\\n",
       "0   300, 1.0, 0.05, 0.5   23.742014  11.945584  16.055556    ...       \n",
       "1   300, 1.0, 0.05, 0.7   23.649653  12.194530  18.555556    ...       \n",
       "2   300, 1.0, 0.05, 0.9   23.268403  12.029715  12.166667    ...       \n",
       "3    300, 1.0, 0.2, 0.5   19.993750   7.076355  19.722222    ...       \n",
       "..                  ...         ...        ...        ...    ...       \n",
       "32   600, 1.0, 0.2, 0.9   19.917361   7.384408  19.222222    ...       \n",
       "33  600, 1.0, 0.35, 0.5   24.411111   4.147089  19.888889    ...       \n",
       "34  600, 1.0, 0.35, 0.7   24.333333   4.419286  19.611111    ...       \n",
       "35  600, 1.0, 0.35, 0.9   24.283681   4.158448  19.500000    ...       \n",
       "\n",
       "     f10, u13   f10, u14   f10, u15   f10, u16  \n",
       "0   21.666667  29.111111  10.222222   9.888889  \n",
       "1   20.666667  34.888889  11.055556  17.055556  \n",
       "2   24.611111  32.000000  15.000000   7.833333  \n",
       "3   14.833333  17.222222  12.722222  11.055556  \n",
       "..        ...        ...        ...        ...  \n",
       "32  15.222222  17.888889   9.555556  11.000000  \n",
       "33  22.222222  22.944444  23.555556  21.777778  \n",
       "34  20.000000  21.111111  23.555556  19.222222  \n",
       "35  20.611111  20.555556  22.722222  22.611111  \n",
       "\n",
       "[36 rows x 163 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 599.14 minutes to run the above function\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "best_parameters_coarse_search,\\\n",
    "best_mean_of_FN_FP_coarse_search,\\\n",
    "std_of_FN_FP_mean_coarse_search = bestParameter_GridSearch(X,\n",
    "                                                           selected_classifier,\n",
    "                                                           selected_parameters,\n",
    "                                                           feature_sets,\n",
    "                                                           feature_files, # meaning users\n",
    "                                                           selected_classifier_name,\n",
    "                                                           'Coarse Grid Search')\n",
    "\n",
    "print('It took {:.2f} minutes to run the above function'.format((time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of the coarse search made with the Isolation Forest classifier are:\n",
      "400, 1.0, 0.2, 0.9\n",
      "The error on those parameters in terms of combined FN and FP rates is 19.8829861111111.\n",
      "The std of this error across all features and participants is 7.249429513727164.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters of the coarse search made with the {} classifier are:\\n{}\"\n",
    "      .format(selected_classifier_name, best_parameters_coarse_search))\n",
    "print('The error on those parameters in terms of combined FN and FP rates is {}.'\n",
    "      .format(best_mean_of_FN_FP_coarse_search))\n",
    "print('The std of this error across all features and participants is {}.'\n",
    "      .format(std_of_FN_FP_mean_coarse_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Grid Search\n",
    "\n",
    "Here we define the parameters for a more refined grid search according to the results of the previous search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for one-class SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nu = [0.001, 0.005, 0.01, 0.015, 0.1, 0.15, 0.2, 0.25, 0.3]        # nu - best was 0.1 (rbf)\n",
    "new_gamma = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2] # gamma - best was 0.1 (rbf)\n",
    "\n",
    "new_def_degree = [3.0]\n",
    "new_def_coef0 = [0.0]\n",
    "\n",
    "# initialize a list of parameters the classifier can take\n",
    "new_parameters_SVM = [{'kernel': ['rbf'],\n",
    "                       'nu': new_nu,\n",
    "                       'degree': new_def_degree,\n",
    "                       'gamma': new_gamma,\n",
    "                       'coef0': new_def_coef0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for Isolation Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [350, 400, 450]           # number of estimators\n",
    "contamination = [0.1, 0.15, 0.2, 0.25] # contamination\n",
    "max_features = [0.8, 0.9, 1.0]         # max features\n",
    "\n",
    "def_samples = [1.0]\n",
    "\n",
    "new_parameters_IF = [{'n_estimators': estimators,\n",
    "                      'max_samples': def_samples,\n",
    "                      'contamination': contamination,\n",
    "                      'max_features': max_features}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters for the coarse grid search is 36.\n"
     ]
    }
   ],
   "source": [
    "selected_parameters_fine_grid_search = findListOfParameters(new_parameters_IF)\n",
    "\n",
    "print(\"The number of parameters for the coarse grid search is {}.\"\n",
    "      .format(len(selected_parameters_fine_grid_search)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the grid search for the parameters is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean FN+FP</th>\n",
       "      <th>std FN+FP</th>\n",
       "      <th>f1, u1</th>\n",
       "      <th>...</th>\n",
       "      <th>f10, u13</th>\n",
       "      <th>f10, u14</th>\n",
       "      <th>f10, u15</th>\n",
       "      <th>f10, u16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350, 1.0, 0.1, 0.8</td>\n",
       "      <td>20.018056</td>\n",
       "      <td>10.369014</td>\n",
       "      <td>15.277778</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>6.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350, 1.0, 0.1, 0.9</td>\n",
       "      <td>20.015972</td>\n",
       "      <td>10.174626</td>\n",
       "      <td>17.388889</td>\n",
       "      <td>...</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>10.444444</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350, 1.0, 0.1, 1.0</td>\n",
       "      <td>19.858333</td>\n",
       "      <td>10.431870</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>15.444444</td>\n",
       "      <td>12.611111</td>\n",
       "      <td>12.055556</td>\n",
       "      <td>4.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350, 1.0, 0.15, 0.8</td>\n",
       "      <td>19.475694</td>\n",
       "      <td>8.788098</td>\n",
       "      <td>15.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>13.444444</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>9.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>450, 1.0, 0.2, 1.0</td>\n",
       "      <td>20.054514</td>\n",
       "      <td>7.293937</td>\n",
       "      <td>19.277778</td>\n",
       "      <td>...</td>\n",
       "      <td>17.722222</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>12.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>450, 1.0, 0.25, 0.8</td>\n",
       "      <td>20.940972</td>\n",
       "      <td>6.274922</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.444444</td>\n",
       "      <td>13.722222</td>\n",
       "      <td>15.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>450, 1.0, 0.25, 0.9</td>\n",
       "      <td>20.946181</td>\n",
       "      <td>6.109828</td>\n",
       "      <td>21.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>17.444444</td>\n",
       "      <td>17.277778</td>\n",
       "      <td>14.111111</td>\n",
       "      <td>11.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>450, 1.0, 0.25, 1.0</td>\n",
       "      <td>20.936458</td>\n",
       "      <td>5.958336</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>17.111111</td>\n",
       "      <td>16.888889</td>\n",
       "      <td>14.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             parameters  mean FN+FP  std FN+FP     f1, u1    ...      \\\n",
       "0    350, 1.0, 0.1, 0.8   20.018056  10.369014  15.277778    ...       \n",
       "1    350, 1.0, 0.1, 0.9   20.015972  10.174626  17.388889    ...       \n",
       "2    350, 1.0, 0.1, 1.0   19.858333  10.431870  12.555556    ...       \n",
       "3   350, 1.0, 0.15, 0.8   19.475694   8.788098  15.555556    ...       \n",
       "..                  ...         ...        ...        ...    ...       \n",
       "32   450, 1.0, 0.2, 1.0   20.054514   7.293937  19.277778    ...       \n",
       "33  450, 1.0, 0.25, 0.8   20.940972   6.274922  19.666667    ...       \n",
       "34  450, 1.0, 0.25, 0.9   20.946181   6.109828  21.444444    ...       \n",
       "35  450, 1.0, 0.25, 1.0   20.936458   5.958336  18.500000    ...       \n",
       "\n",
       "     f10, u13   f10, u14   f10, u15   f10, u16  \n",
       "0   14.500000  15.333333   7.666667   6.777778  \n",
       "1   13.333333  14.333333  10.444444   5.555556  \n",
       "2   15.444444  12.611111  12.055556   4.111111  \n",
       "3   13.444444  12.333333  10.333333   9.388889  \n",
       "..        ...        ...        ...        ...  \n",
       "32  17.722222  15.166667  13.333333  12.722222  \n",
       "33  15.000000  17.444444  13.722222  15.944444  \n",
       "34  17.444444  17.277778  14.111111  11.777778  \n",
       "35  18.666667  17.111111  16.888889  14.333333  \n",
       "\n",
       "[36 rows x 163 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 436.79 minutes to run the above function\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "best_parameters_fine_search,\\\n",
    "best_mean_of_FN_FP_fine_search,\\\n",
    "std_of_FN_FP_mean_fine_search = bestParameter_GridSearch(X, \n",
    "                                                         selected_classifier, \n",
    "                                                         selected_parameters_fine_grid_search,\n",
    "                                                         feature_sets, \n",
    "                                                         feature_files,\n",
    "                                                         selected_classifier_name, \n",
    "                                                         'Fine Grid Search')\n",
    "\n",
    "print('It took {:.2f} minutes to run the above function'.format((time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of the fine search made with the Isolation Forest classifier are:\n",
      "350, 1.0, 0.15, 1.0\n",
      "The error on those parameters in terms of combined FN and FP rates is 19.1763888888889.\n",
      "The std of this error across all features and participants is 8.642370569389048.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters of the fine search made with the {} classifier are:\\n{}\"\n",
    "      .format(selected_classifier_name, best_parameters_fine_search))\n",
    "print('The error on those parameters in terms of combined FN and FP rates is {}.'\n",
    "      .format(best_mean_of_FN_FP_fine_search))\n",
    "print('The std of this error across all features and participants is {}.'\n",
    "      .format(std_of_FN_FP_mean_fine_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop a cleaner csv with only the best parameters\n",
    "\n",
    "In order to do that we will pick the best parameters and drop them in a smaller csv. We will use the name of the classifier in the title. The goal is that for every classifier that there is such a file for every classifier that is being used in the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe with the best parameters is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter name</th>\n",
       "      <th>parameter value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_samples</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contamination</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_features</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parameter name parameter value\n",
       "0   n_estimators             350\n",
       "1    max_samples             1.0\n",
       "2  contamination            0.15\n",
       "3   max_features             1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split he list according to the comma and space characters that separate the params (', ')\n",
    "best_params_list = best_parameters_fine_search.split(', ')\n",
    "\n",
    "best_params_list = [best_params_list[0]] + [p for p in best_params_list[1:]]\n",
    "\n",
    "# put them to a dataframe\n",
    "best_params_df = pd.DataFrame({'parameter name': param_names_IF,\n",
    "                               'parameter value': best_params_list})\n",
    "\n",
    "print(\"The dataframe with the best parameters is:\\n\")\n",
    "display(best_params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a csv using the name of the classifier as the file name\n",
    "best_params_df.to_csv(target_path_rel + 'Optimal Parameters --- {}.csv'\n",
    "                      .format(selected_classifier_name), \n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the score and std of the best params\n",
    "fd = open(target_path_rel + 'Optimal Parameters --- {}.csv'.format(selected_classifier_name),'a')\n",
    "fd.write('--------------------------------------------------------------------------------\\n')\n",
    "fd.write('--------------------------------------------------------------------------------\\n')\n",
    "fd.write('The mean error across features and users of the above parameters is {:.4f}\\n'\n",
    "         .format(best_mean_of_FN_FP_fine_search))\n",
    "fd.write('The std of the aforementioned error is {:.4f}\\n'.format(std_of_FN_FP_mean_fine_search))\n",
    "fd.write('--------------------------------------------------------------------------------\\n')\n",
    "fd.write('The error for every separate case is measured as the mean of FN rate and FP rate')\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
