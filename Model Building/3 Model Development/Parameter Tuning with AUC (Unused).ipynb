{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Parameters\n",
    "\n",
    "The purpose of this notebook is to find the best parameters for the different sets of features. In order to do so, a model needs to be selected, along with the parameter space that will be searched. First a coarse grid search is performed, and then a more narrow one. The result of a notebook end to end run, should be a csv file with a specified name that mentions the model it is for. The csv for an SVM for example should look like:\n",
    "\n",
    "    parameter, value  <-- (header)\n",
    "    kernel, rbf\n",
    "    nu, 0.01\n",
    "    degree, 3\n",
    "    gamma, 0.05\n",
    "    coef0, 0.0\n",
    "    \n",
    "In order to successfully run the notebook for its purpose, the sections that need to be modified for a new algorithm are:\n",
    "\n",
    "    1. Model Selection (where a new model is initialized)\n",
    "    2. Parameter Space - Coarse (where the selected parameters need to correspond to the algorithm)\n",
    "    3. Drop a cleaner csv with only the best parameters (where the parameter names need to be set\n",
    "       accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files selected from the directory is 16.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "from time import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "rows_each = 60\n",
    "\n",
    "# specify the place from where we will use the data\n",
    "source_path_rel = 'data/Main collection - features/'\n",
    "\n",
    "# specify the target path for dropping the parameters\n",
    "target_path_rel = 'data/Main collection - results/parameters/'\n",
    "\n",
    "# find the file names in the directory\n",
    "feature_files = os.listdir(source_path_rel)\n",
    "\n",
    "# remove the readme, and the Giorgos files\n",
    "feature_files.remove('README.md')\n",
    "feature_files.remove('Giorgos Mon 19.csv')\n",
    "feature_files.remove('Giorgos Wed 21.csv')\n",
    "feature_files.remove('Giorgos Fri 23.csv')\n",
    "feature_files.remove('Giorgos Mon 26.csv')\n",
    "feature_files.remove('best ratios by multiclass RF')\n",
    "\n",
    "print(\"The number of files selected from the directory is {}.\".format(len(feature_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING OPTIONS\n",
    "np.set_printoptions(threshold=80)\n",
    "pd.set_option('display.max_rows', 8)\n",
    "pd.set_option('display.max_columns', 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all data in a single DataFrame\n",
    "\n",
    "The process here is to sample 60 locks from each participant. Some participants have more than 60 locks and in that case we select the lokcs randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe that holds the data is as follows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB_mil</th>\n",
       "      <th>AB_xyz</th>\n",
       "      <th>AB|AC_mil</th>\n",
       "      <th>AB|AC_xyz</th>\n",
       "      <th>...</th>\n",
       "      <th>zSpeed_range</th>\n",
       "      <th>zSpeed_skew</th>\n",
       "      <th>zSpeed_std</th>\n",
       "      <th>zSpeed_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434.0</td>\n",
       "      <td>258.930923</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.655369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081136</td>\n",
       "      <td>-0.149765</td>\n",
       "      <td>0.184878</td>\n",
       "      <td>0.034180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502.0</td>\n",
       "      <td>297.418459</td>\n",
       "      <td>0.548035</td>\n",
       "      <td>0.629426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.088235</td>\n",
       "      <td>1.069284</td>\n",
       "      <td>0.282818</td>\n",
       "      <td>0.079986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529.0</td>\n",
       "      <td>339.767000</td>\n",
       "      <td>0.549325</td>\n",
       "      <td>0.757873</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.249953</td>\n",
       "      <td>0.062477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>503.0</td>\n",
       "      <td>301.571361</td>\n",
       "      <td>0.558269</td>\n",
       "      <td>0.689733</td>\n",
       "      <td>...</td>\n",
       "      <td>2.217469</td>\n",
       "      <td>1.207258</td>\n",
       "      <td>0.290968</td>\n",
       "      <td>0.084663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>445.0</td>\n",
       "      <td>158.355584</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.820856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.489388</td>\n",
       "      <td>0.124969</td>\n",
       "      <td>0.015617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>436.0</td>\n",
       "      <td>138.876355</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.597251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491597</td>\n",
       "      <td>0.393809</td>\n",
       "      <td>0.109206</td>\n",
       "      <td>0.011926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>495.0</td>\n",
       "      <td>183.983717</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.818607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897829</td>\n",
       "      <td>-0.483202</td>\n",
       "      <td>0.137261</td>\n",
       "      <td>0.018841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>477.0</td>\n",
       "      <td>175.668280</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.857197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>0.742492</td>\n",
       "      <td>0.105224</td>\n",
       "      <td>0.011072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 916 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AB_mil      AB_xyz  AB|AC_mil  AB|AC_xyz     ...      zSpeed_range  \\\n",
       "0     434.0  258.930923   0.418919   0.655369     ...          1.081136   \n",
       "1     502.0  297.418459   0.548035   0.629426     ...          2.088235   \n",
       "2     529.0  339.767000   0.549325   0.757873     ...          1.235294   \n",
       "3     503.0  301.571361   0.558269   0.689733     ...          2.217469   \n",
       "..      ...         ...        ...        ...     ...               ...   \n",
       "956   445.0  158.355584   0.654412   0.820856     ...          0.558824   \n",
       "957   436.0  138.876355   0.586022   0.597251     ...          0.491597   \n",
       "958   495.0  183.983717   0.651316   0.818607     ...          0.897829   \n",
       "959   477.0  175.668280   0.671831   0.857197     ...          0.421429   \n",
       "\n",
       "     zSpeed_skew  zSpeed_std  zSpeed_var  \n",
       "0      -0.149765    0.184878    0.034180  \n",
       "1       1.069284    0.282818    0.079986  \n",
       "2       0.071162    0.249953    0.062477  \n",
       "3       1.207258    0.290968    0.084663  \n",
       "..           ...         ...         ...  \n",
       "956     0.489388    0.124969    0.015617  \n",
       "957     0.393809    0.109206    0.011926  \n",
       "958    -0.483202    0.137261    0.018841  \n",
       "959     0.742492    0.105224    0.011072  \n",
       "\n",
       "[960 rows x 916 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the data frame with the locks that will be used\n",
    "X = pd.DataFrame()\n",
    "\n",
    "for i, file in enumerate(feature_files):\n",
    "    \n",
    "    # read each features file into a df\n",
    "    df = pd.read_csv(source_path_rel+file)\n",
    "    \n",
    "    # select a sample of 60 values (without replacement)\n",
    "    df = df.sample(n=rows_each, random_state=random_state, axis=0)\n",
    "    \n",
    "    # sort the sampled dataframe by index \n",
    "    df.index = range(df.shape[0])\n",
    "    \n",
    "    # add the data to the bigger dataframe\n",
    "    X = pd.concat([X, df.loc[:, :]], ignore_index=True)\n",
    "    \n",
    "print(\"The dataframe that holds the data is as follows:\")\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature sets selection\n",
    "\n",
    "After loading the data, the next step is to select features. The parameter tuning will be across all the feature groups. There will be 10 groups of features that we will deal with here. These 10 groups of features can be grouped in 3 broader groups which are the overal/holistic features, the distances and the ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRatioFeatureIds(file_name, n=30):\n",
    "    \"\"\" Loads the file with features. \"\"\"\n",
    "    df = pd.read_csv('data/Main collection - features/best ratios by multiclass RF/' + file_name)\n",
    "    return df.loc[:n-1, 'feature id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMagnitudes(f1, f2):\n",
    "    \"\"\" Selects the features for both f1 and f2 lists that start with mag. \"\"\"\n",
    "    ff = [f for f in f1 if f[:3]=='mag']\n",
    "    ff.extend([f for f in f2 if f[:3]=='mag'])\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features\n",
    "all_features = X.columns.values.tolist()\n",
    "\n",
    "# find all positional features\n",
    "pos_features = [f for f in all_features if f[1:4]=='Pos' and f[4]!='I']\n",
    "\n",
    "# find all position intervals\n",
    "posInc_features = [f for f in all_features if f[1:7]=='PosInc' or f[3:9]=='PosInc']\n",
    "\n",
    "# find all speed intervals\n",
    "speed_features = [f for f in all_features if f[1:6]=='Speed' or f[3:8]=='Speed']\n",
    "\n",
    "# find all x axis features\n",
    "x_features_pos_posInc_speed = [f for f in pos_features if f[0]=='x'] + \\\n",
    "                                [f for f in posInc_features if f[0]=='x'] + \\\n",
    "                                [f for f in speed_features if f[0]=='x']\n",
    "\n",
    "# find all y axis features\n",
    "y_features_pos_posInc_speed = [f for f in pos_features if f[0]=='y'] + \\\n",
    "                                [f for f in posInc_features if f[0]=='y'] + \\\n",
    "                                [f for f in speed_features if f[0]=='y']\n",
    "\n",
    "# find all z axis features\n",
    "z_features_pos_posInc_speed = [f for f in pos_features if f[0]=='z'] + \\\n",
    "                                [f for f in posInc_features if f[0]=='z'] + \\\n",
    "                                [f for f in speed_features if f[0]=='z']\n",
    "\n",
    "# find all magnitude features\n",
    "magnitude_features = findMagnitudes(posInc_features, speed_features)\n",
    "\n",
    "# combine best overall features\n",
    "best_overall_features = x_features_pos_posInc_speed + y_features_pos_posInc_speed\n",
    "\n",
    "# combine all overall features\n",
    "all_overall_features = pos_features + posInc_features + speed_features\n",
    "\n",
    "## Distances next ##\n",
    "\n",
    "# find all euclidean distances\n",
    "euc_dist_features = [f for f in all_features if f[2]=='_' and f[-3:]=='xyz']\n",
    "\n",
    "# find all temporal distances\n",
    "mil_dist_features = [f for f in all_features if f[2]=='_' and f[-3:]=='mil']\n",
    "\n",
    "# combine euc and mil distances\n",
    "all_distances = euc_dist_features + mil_dist_features\n",
    "\n",
    "## Ratios next ##\n",
    "\n",
    "# find the selected euclidean ratios\n",
    "euc_all_ratio_features = [f for f in all_features if f[2]=='|' and f[-3:]=='xyz']\n",
    "\n",
    "# find the selected temporal ratios\n",
    "mil_all_ratio_features = [f for f in all_features if f[2]=='|' and f[-3:]=='mil']\n",
    "\n",
    "# combine euc and temp ratios\n",
    "all_ratio_features = euc_all_ratio_features + mil_all_ratio_features\n",
    "\n",
    "## best ratios ##\n",
    "\n",
    "# find the selected euclidean ratios\n",
    "euc_best_ratio_features = loadRatioFeatureIds('Euclidean distance ratios.csv')\n",
    "\n",
    "# find the selected temporal ratios\n",
    "mil_best_ratio_features = loadRatioFeatureIds('Temporal distance ratios.csv')\n",
    "\n",
    "# all best ratio features\n",
    "all_best_ratio_features = pd.concat([euc_best_ratio_features, \n",
    "                                     mil_best_ratio_features], \n",
    "                                    ignore_index=True)\n",
    "\n",
    "## Best all next ##\n",
    "\n",
    "## best Combinations ## (1)\n",
    "best_overall_distances = best_overall_features + all_distances\n",
    "best_overall_ratios = best_overall_features + list(all_best_ratio_features)\n",
    "best_ratios_distances = list(all_best_ratio_features) + all_distances\n",
    "best_overall_distances_ratios = best_overall_features + all_distances + list(all_best_ratio_features)\n",
    "\n",
    "## best Combinations ## (2 - unused)\n",
    "pos_with_distances = pos_features + all_distances\n",
    "pos_with_best_ratios = pos_features + list(all_best_ratio_features)\n",
    "pos_with_distances_with_best_ratios = pos_features + all_distances + list(all_best_ratio_features)\n",
    "\n",
    "# all features\n",
    "#all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [pos_features, posInc_features, speed_features, euc_dist_features,\n",
    "                mil_dist_features, euc_all_ratio_features, mil_all_ratio_features]\n",
    "\n",
    "feature_set_names = ['positions', 'position intervals', 'speed intervals', 'euclidean distances',\n",
    "                     'temporal distances', 'euclidean ratios (all 356)', 'temporal ratios (all 356)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [best_overall_distances_ratios]\n",
    "\n",
    "feature_set_names = ['best overall dist ratios']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "The next step is to initialize the models and make a selection of the one that will be used. Because this notebook is supposed to use only one model, the selected classifier needs to be selected in the next cell by commenting out the remaining options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# selected_classifier = svm.OneClassSVM()\n",
    "# selected_classifier_name = 'one-class SVM'\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "selected_classifier = IsolationForest()\n",
    "selected_classifier_name = 'Isolation Forest'\n",
    "\n",
    "# from sklearn.covariance import EllipticEnvelope\n",
    "# selected_classifier = EllipticEnvelope()\n",
    "# selected_classifier_name = 'Elliptic Envelope'\n",
    "\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "# selected_classifier = LocalOutlierFactor()\n",
    "# selected_classifier_name = 'Local Outlier Factor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Space - Coarse\n",
    "\n",
    "Here for every algorithm that will be probed, we will define the parameter space for a coarse grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for one-class SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = [0.1, 0.3, 0.5, 0.7, 0.9]    # nu\n",
    "degree = [1, 2, 3, 4]             # degree (poly)\n",
    "gamma = [0.1, 0.3, 0.5, 0.7, 0.9] # gamma (rbf, poly sigmoid)\n",
    "coef0 = [0.1, 0.3, 0.5, 0.7, 0.9] # coef0 (poly, sigmoid)\n",
    "\n",
    "def_degree = [3.0]\n",
    "def_gamma = ['auto']\n",
    "def_coef0 = [0.0]\n",
    "\n",
    "# initialize a list of parameters the classifier can take\n",
    "parameters_SVM = [{'kernel': ['linear'],\n",
    "                   'nu': nu,\n",
    "                   'degree': def_degree,\n",
    "                   'gamma': def_gamma,\n",
    "                   'coef0': def_coef0},\n",
    "                  {'kernel': ['rbf'],\n",
    "                   'nu': nu,\n",
    "                   'degree': def_degree,\n",
    "                   'gamma': gamma,\n",
    "                   'coef0': def_coef0},\n",
    "                  {'kernel': ['poly'],\n",
    "                   'nu': nu,\n",
    "                   'degree': degree,\n",
    "                   'gamma': gamma,\n",
    "                   'coef0': coef0},\n",
    "                  {'kernel': ['sigmoid'],\n",
    "                   'nu': nu,\n",
    "                   'degree': def_degree,\n",
    "                   'gamma': gamma,\n",
    "                   'coef0': coef0}]\n",
    "\n",
    "param_names_SVM = ['kernel', 'nu', 'degree', 'gamma', 'coef0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a list of parameters the classifier can take\n",
    "parameters_SVM_only_rbf = [{'kernel': ['rbf'],\n",
    "                           'nu': nu,\n",
    "                           'degree': def_degree,\n",
    "                           'gamma': gamma,\n",
    "                           'coef0': def_coef0}]\n",
    "\n",
    "param_names_SVM = ['kernel', 'nu', 'degree', 'gamma', 'coef0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for Isolation Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [300, 400, 500, 600]      # number of estimators\n",
    "contamination = [0.05, 0.2, 0.35] # contamination\n",
    "max_features = [0.5, 0.7, 0.9]    # max features\n",
    "\n",
    "def_samples = [1.0]\n",
    "\n",
    "parameters_IF = [{'n_estimators': estimators,\n",
    "                  'max_samples': def_samples,\n",
    "                  'contamination': contamination,\n",
    "                  'max_features': max_features}]\n",
    "\n",
    "param_names_IF = ['n_estimators', 'max_samples', 'contamination', 'max_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make list of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findListOfParameters(parameters):\n",
    "    \"\"\" Returns all combinations by the dictionary values, in a list of dictionaries \"\"\"\n",
    "    return [tup for d in parameters for tup in list(itertools.product(*d.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_parameters = findListOfParameters(parameters_IF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse Grid Search\n",
    "\n",
    "In order to find the optimal parameter combination, we will run the selected model for every user and every group of features. Then we will select the parameters with the best mean score across all combinations of users with features. The data structure that we will use will look like:\n",
    "\n",
    "|                 | f1,u1 | f1,u2 |  ...  | f1,uN |  ...  | fN,u1 | fN,u2 |  ...  | fN,uN |\n",
    "|-----------------|-------|-------|-------|-------|-------|-------|-------|-------|-------|\n",
    "|   parameters1   |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |\n",
    "|   parameters2   |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |\n",
    "|       ...       |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |\n",
    "|   parametersN   |  val  |  val  |  ...  |  val  |  ...  |  val  |  val  |  ...  |  val  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import interp\n",
    "from sklearn.metrics import auc, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addParamsToClf(clf, p, clf_name):\n",
    "    \"\"\" Adds the parameters of the classifier according to its name. \"\"\"\n",
    "    \n",
    "    if clf_name == 'one-class SVM':\n",
    "        clf.set_params(kernel=p[0], nu=p[1], degree=p[2], gamma=p[3], coef0=p[4])\n",
    "    elif clf_name == 'Isolation Forest':\n",
    "        clf.set_params(n_estimators=p[0], max_samples=p[1], contamination=p[2], max_features=p[3])\n",
    "    else:\n",
    "        raise ValueError('The classifier name is not enlisted')\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyWithCV(X_positive, X_negative, clf, scaler, folds=5, random_state=0):\n",
    "    \"\"\" Finds the convergence line of a classifier, in different samples. \"\"\"\n",
    "    \n",
    "    # initialize a cross validation object\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    mean_FPR = np.linspace(0, 1, 100)\n",
    "\n",
    "    TPRs_cv = []\n",
    "        \n",
    "    for train, test in kf.split(X_positive):\n",
    "\n",
    "        # fit the scalar\n",
    "        scaler.fit(X_positive.loc[train, :])\n",
    "\n",
    "        # scale all data before fitting the classifier or making predictions\n",
    "        X_pos_transformed_train = scaler.transform(X_positive.loc[train, :])\n",
    "        X_pos_transformed_test = scaler.transform(X_positive.loc[test, :])\n",
    "        X_neg_transformed_test = scaler.transform(X_negative)\n",
    "        \n",
    "        # fit the classifier\n",
    "        clf.fit(X_pos_transformed_train)\n",
    "\n",
    "        # make prediction with decision function on Positive data\n",
    "        prediction_pos_DF = clf.decision_function(X_pos_transformed_test)\n",
    "\n",
    "        # make prediction with decision function on Negative data\n",
    "        prediction_neg_DF = clf.decision_function(X_neg_transformed_test)\n",
    "        \n",
    "        y_true = [1 for _ in range(prediction_pos_DF.shape[0])] + [0 for _ in range(prediction_neg_DF.shape[0])]\n",
    "        y_scores = [s for s in prediction_pos_DF] + [s for s in prediction_neg_DF]\n",
    "        \n",
    "        # find values for the ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n",
    "            \n",
    "        # interpolate the linear space of mean_FPR to the fpr, tpr coordinates\n",
    "        TPRs_cv.append(interp(mean_FPR, fpr, tpr))\n",
    "        TPRs_cv[-1][0] = 0.0\n",
    "            \n",
    "    # find the mean curve\n",
    "    mean_tpr = np.mean(TPRs_cv, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    \n",
    "    return auc(mean_FPR, mean_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParameter_GridSearch(X_all, clf, params, features, users, clf_name, search_type,\n",
    "                             locks_per_participant=60):\n",
    "    \"\"\" Finds the best set of parameters across all users and features \"\"\"\n",
    "    \n",
    "    # initialize the dataframe for all values\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    # initialize a minmax scalar\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    for cc, p in enumerate(params):\n",
    "        \n",
    "        # add the parameters to the classifier according to its name\n",
    "        classifier = addParamsToClf(selected_classifier, p, selected_classifier_name)\n",
    "        \n",
    "        if clf_name=='one-class SVM':\n",
    "            param_string = '{}, {}, {}, {}, {}'.format(*p)\n",
    "        elif clf_name=='Isolation Forest':\n",
    "            param_string = '{}, {}, {}, {}'.format(*p)\n",
    "        else:\n",
    "            raise ValueError(\"Something is wrong with the classifier name\")\n",
    "        \n",
    "        print(\"Currently working on the {}/{} set of parameters which is: \"\n",
    "              .format(cc+1, len(params))+param_string+\" ...\")\n",
    "        \n",
    "        for i, f in enumerate(features):\n",
    "\n",
    "            for j, u in enumerate(users):\n",
    "                \n",
    "                # define the column name\n",
    "                col = 'f'+str(i+1)+', u'+str(j+1)\n",
    "                \n",
    "                # find the starting index of the original dataframe\n",
    "                idx = j*locks_per_participant\n",
    "        \n",
    "                # find the mask for positive values to slice the dataset\n",
    "                positive_mask = X_all.index.isin(range(idx, idx+locks_per_participant))\n",
    "\n",
    "                # find the lines that correspond to this participant and the feature set\n",
    "                X_pos = X_all.loc[positive_mask, f]\n",
    "\n",
    "                # find the lines that correspond to all other participants and the feature set\n",
    "                X_neg = X_all.loc[~positive_mask, f]\n",
    "\n",
    "                # reset the index of the features dataframe\n",
    "                X_pos.index = range(X_pos.shape[0])\n",
    "                \n",
    "                # reset the index of the features dataframe\n",
    "                X_neg.index = range(X_neg.shape[0])\n",
    "                \n",
    "                # run classify with cv\n",
    "                df.loc[param_string, col] = classifyWithCV(X_pos, X_neg, classifier, scaler)\n",
    "                \n",
    "            # give some feedback that the feature is finished\n",
    "            print('The models are finished for {}/10 features'.format(i+1))\n",
    "            \n",
    "        clear_output()\n",
    "            \n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    # set new column for the parameters\n",
    "    df.loc[:, 'parameters'] = df.index\n",
    "    \n",
    "    # make new column for the mean scores\n",
    "    df.loc[:, 'mean AUC'] = np.mean(df.loc[:, cols], axis=1)\n",
    "    \n",
    "    # make new column for the mean scores\n",
    "    df.loc[:, 'std AUC'] = np.std(df.loc[:, cols], axis=1)\n",
    "    \n",
    "    # reset the index of the features dataframe\n",
    "    df.index = range(df.shape[0])\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    # reorder the columns\n",
    "    cols = cols[-3:] + cols[:-3]\n",
    "    \n",
    "    df = df[cols]\n",
    "    \n",
    "    print(\"The result of the grid search for the parameters is:\\n\")\n",
    "    \n",
    "    # show the dataframe\n",
    "    display(df)\n",
    "    \n",
    "    # log the results\n",
    "    df.to_csv(target_path_rel + '{} logs for {} (AUC).csv'.format(search_type, clf_name), index=False)\n",
    "    \n",
    "    # find the winning line\n",
    "    winning_line = df.loc[df.loc[:, 'mean AUC'].idxmax(), :]\n",
    "        \n",
    "    # return the parameter with the smallest sum of mean FN and FP\n",
    "    return winning_line['parameters'], winning_line['mean AUC'], winning_line['std AUC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected parameter sets are 36.\n"
     ]
    }
   ],
   "source": [
    "print('The selected parameter sets are {}.'. format(len(selected_parameters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the grid search for the parameters is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean AUC</th>\n",
       "      <th>std AUC</th>\n",
       "      <th>f1, u1</th>\n",
       "      <th>...</th>\n",
       "      <th>f1, u13</th>\n",
       "      <th>f1, u14</th>\n",
       "      <th>f1, u15</th>\n",
       "      <th>f1, u16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300, 1.0, 0.05, 0.5</td>\n",
       "      <td>0.974548</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.986027</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300, 1.0, 0.05, 0.7</td>\n",
       "      <td>0.974621</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951010</td>\n",
       "      <td>0.973737</td>\n",
       "      <td>0.987710</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300, 1.0, 0.05, 0.9</td>\n",
       "      <td>0.976441</td>\n",
       "      <td>0.015176</td>\n",
       "      <td>0.981650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956229</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.987542</td>\n",
       "      <td>0.993939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300, 1.0, 0.2, 0.5</td>\n",
       "      <td>0.974779</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.979293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947475</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.986195</td>\n",
       "      <td>0.994613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>600, 1.0, 0.2, 0.9</td>\n",
       "      <td>0.976452</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.980135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947811</td>\n",
       "      <td>0.976599</td>\n",
       "      <td>0.988047</td>\n",
       "      <td>0.994949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>600, 1.0, 0.35, 0.5</td>\n",
       "      <td>0.977031</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>0.980135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952189</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.988552</td>\n",
       "      <td>0.994949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>600, 1.0, 0.35, 0.7</td>\n",
       "      <td>0.975705</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.978788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947643</td>\n",
       "      <td>0.972559</td>\n",
       "      <td>0.985354</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>600, 1.0, 0.35, 0.9</td>\n",
       "      <td>0.975989</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.979630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950505</td>\n",
       "      <td>0.974916</td>\n",
       "      <td>0.985859</td>\n",
       "      <td>0.994613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             parameters  mean AUC   std AUC    f1, u1    ...      f1, u13  \\\n",
       "0   300, 1.0, 0.05, 0.5  0.974548  0.016361  0.981818    ...     0.944444   \n",
       "1   300, 1.0, 0.05, 0.7  0.974621  0.015621  0.979966    ...     0.951010   \n",
       "2   300, 1.0, 0.05, 0.9  0.976441  0.015176  0.981650    ...     0.956229   \n",
       "3    300, 1.0, 0.2, 0.5  0.974779  0.014848  0.979293    ...     0.947475   \n",
       "..                  ...       ...       ...       ...    ...          ...   \n",
       "32   600, 1.0, 0.2, 0.9  0.976452  0.014705  0.980135    ...     0.947811   \n",
       "33  600, 1.0, 0.35, 0.5  0.977031  0.013886  0.980135    ...     0.952189   \n",
       "34  600, 1.0, 0.35, 0.7  0.975705  0.014373  0.978788    ...     0.947643   \n",
       "35  600, 1.0, 0.35, 0.9  0.975989  0.014400  0.979630    ...     0.950505   \n",
       "\n",
       "     f1, u14   f1, u15   f1, u16  \n",
       "0   0.968182  0.986027  0.994444  \n",
       "1   0.973737  0.987710  0.994444  \n",
       "2   0.975253  0.987542  0.993939  \n",
       "3   0.972222  0.986195  0.994613  \n",
       "..       ...       ...       ...  \n",
       "32  0.976599  0.988047  0.994949  \n",
       "33  0.976431  0.988552  0.994949  \n",
       "34  0.972559  0.985354  0.994444  \n",
       "35  0.974916  0.985859  0.994613  \n",
       "\n",
       "[36 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 252.49 minutes to run the above function\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "best_parameters_coarse_search,\\\n",
    "best_mean_of_AUC_coarse_search,\\\n",
    "std_of_AUC_mean_coarse_search = bestParameter_GridSearch(X,\n",
    "                                                         selected_classifier,\n",
    "                                                         selected_parameters,\n",
    "                                                         feature_sets,\n",
    "                                                         feature_files, # meaning users\n",
    "                                                         selected_classifier_name,\n",
    "                                                         'Coarse Grid Search')\n",
    "\n",
    "print('It took {:.2f} minutes to run the above function'.format((time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of the coarse search made with the Isolation Forest classifier are:\n",
      "600, 1.0, 0.2, 0.5\n",
      "The error on those parameters in terms of AUC scores is 0.9774936868686869.\n",
      "The std of this error across all features and participants is 0.015097959824428575.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters of the coarse search made with the {} classifier are:\\n{}\"\n",
    "      .format(selected_classifier_name, best_parameters_coarse_search))\n",
    "print('The error on those parameters in terms of AUC scores is {}.'\n",
    "      .format(best_mean_of_AUC_coarse_search))\n",
    "print('The std of this error across all features and participants is {}.'\n",
    "      .format(std_of_AUC_mean_coarse_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Grid Search\n",
    "\n",
    "Here we define the parameters for a more refined grid search according to the results of the previous search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for one-class SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_nu = [0.001, 0.005, 0.01, 0.015, 0.1, 0.15, 0.2, 0.25, 0.3]        # nu - best was 0.1 (rbf)\n",
    "new_gamma = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2] # gamma - best was 0.1 (rbf)\n",
    "\n",
    "new_def_degree = [3.0]\n",
    "new_def_coef0 = [0.0]\n",
    "\n",
    "# initialize a list of parameters the classifier can take\n",
    "new_parameters_SVM = [{'kernel': ['rbf'],\n",
    "                       'nu': new_nu,\n",
    "                       'degree': new_def_degree,\n",
    "                       'gamma': new_gamma,\n",
    "                       'coef0': new_def_coef0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters for Isolation Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [350, 400, 450]           # number of estimators\n",
    "contamination = [0.1, 0.15, 0.2, 0.25] # contamination\n",
    "max_features = [0.4, 0.5, 1.0]         # max features\n",
    "\n",
    "# for group 25 specifics\n",
    "estimators = [550, 600, 650]                           # number of estimators\n",
    "contamination = [0.1, 0.15, 0.2, 0.25, 0.3]            # contamination\n",
    "max_features = [0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65] # max features\n",
    "\n",
    "\n",
    "def_samples = [1.0]\n",
    "\n",
    "new_parameters_IF = [{'n_estimators': estimators,\n",
    "                      'max_samples': def_samples,\n",
    "                      'contamination': contamination,\n",
    "                      'max_features': max_features}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters for the coarse grid search is 105.\n"
     ]
    }
   ],
   "source": [
    "selected_parameters_fine_grid_search = findListOfParameters(new_parameters_IF)\n",
    "\n",
    "print(\"The number of parameters for the coarse grid search is {}.\"\n",
    "      .format(len(selected_parameters_fine_grid_search)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the grid search for the parameters is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>mean AUC</th>\n",
       "      <th>std AUC</th>\n",
       "      <th>f1, u1</th>\n",
       "      <th>...</th>\n",
       "      <th>f1, u13</th>\n",
       "      <th>f1, u14</th>\n",
       "      <th>f1, u15</th>\n",
       "      <th>f1, u16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550, 1.0, 0.1, 0.35</td>\n",
       "      <td>0.976652</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.977609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951010</td>\n",
       "      <td>0.975589</td>\n",
       "      <td>0.985354</td>\n",
       "      <td>0.994276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550, 1.0, 0.1, 0.4</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.979630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949832</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.985354</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550, 1.0, 0.1, 0.45</td>\n",
       "      <td>0.976052</td>\n",
       "      <td>0.015368</td>\n",
       "      <td>0.977609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946970</td>\n",
       "      <td>0.976431</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.994781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550, 1.0, 0.1, 0.5</td>\n",
       "      <td>0.976168</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.981313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950505</td>\n",
       "      <td>0.974242</td>\n",
       "      <td>0.985690</td>\n",
       "      <td>0.994613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>650, 1.0, 0.3, 0.5</td>\n",
       "      <td>0.976926</td>\n",
       "      <td>0.014978</td>\n",
       "      <td>0.982828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.987205</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>650, 1.0, 0.3, 0.55</td>\n",
       "      <td>0.976357</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.977946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.973401</td>\n",
       "      <td>0.985354</td>\n",
       "      <td>0.994613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>650, 1.0, 0.3, 0.6</td>\n",
       "      <td>0.976357</td>\n",
       "      <td>0.014910</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950337</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>0.985185</td>\n",
       "      <td>0.994613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>650, 1.0, 0.3, 0.65</td>\n",
       "      <td>0.977041</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.978620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950673</td>\n",
       "      <td>0.975253</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.994444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              parameters  mean AUC   std AUC    f1, u1    ...      f1, u13  \\\n",
       "0    550, 1.0, 0.1, 0.35  0.976652  0.013936  0.977609    ...     0.951010   \n",
       "1     550, 1.0, 0.1, 0.4  0.976431  0.014323  0.979630    ...     0.949832   \n",
       "2    550, 1.0, 0.1, 0.45  0.976052  0.015368  0.977609    ...     0.946970   \n",
       "3     550, 1.0, 0.1, 0.5  0.976168  0.014660  0.981313    ...     0.950505   \n",
       "..                   ...       ...       ...       ...    ...          ...   \n",
       "101   650, 1.0, 0.3, 0.5  0.976926  0.014978  0.982828    ...     0.949495   \n",
       "102  650, 1.0, 0.3, 0.55  0.976357  0.014522  0.977946    ...     0.951515   \n",
       "103   650, 1.0, 0.3, 0.6  0.976357  0.014910  0.981481    ...     0.950337   \n",
       "104  650, 1.0, 0.3, 0.65  0.977041  0.013336  0.978620    ...     0.950673   \n",
       "\n",
       "      f1, u14   f1, u15   f1, u16  \n",
       "0    0.975589  0.985354  0.994276  \n",
       "1    0.977778  0.985354  0.994444  \n",
       "2    0.976431  0.986869  0.994781  \n",
       "3    0.974242  0.985690  0.994613  \n",
       "..        ...       ...       ...  \n",
       "101  0.977778  0.987205  0.994444  \n",
       "102  0.973401  0.985354  0.994613  \n",
       "103  0.975758  0.985185  0.994613  \n",
       "104  0.975253  0.984848  0.994444  \n",
       "\n",
       "[105 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 243.14 minutes to run the above function\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "best_parameters_fine_search,\\\n",
    "best_mean_of_AUC_fine_search,\\\n",
    "std_of_AUC_mean_fine_search = bestParameter_GridSearch(X, \n",
    "                                                       selected_classifier, \n",
    "                                                       selected_parameters_fine_grid_search,\n",
    "                                                       feature_sets, \n",
    "                                                       feature_files,\n",
    "                                                       selected_classifier_name, \n",
    "                                                       'Fine Grid Search')\n",
    "\n",
    "print('It took {:.2f} minutes to run the above function'.format((time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters of the fine search made with the Isolation Forest classifier are:\n",
      "550, 1.0, 0.2, 0.45\n",
      "The error on those parameters in terms of AUC scores is 0.9777777777777777.\n",
      "The std of this error across all features and participants is 0.013064097807381103.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters of the fine search made with the {} classifier are:\\n{}\"\n",
    "      .format(selected_classifier_name, best_parameters_fine_search))\n",
    "print('The error on those parameters in terms of AUC scores is {}.'\n",
    "      .format(best_mean_of_AUC_fine_search))\n",
    "print('The std of this error across all features and participants is {}.'\n",
    "      .format(std_of_AUC_mean_fine_search))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop a cleaner csv with only the best parameters\n",
    "\n",
    "In order to do that we will pick the best parameters and drop them in a smaller csv. We will use the name of the classifier in the title. The goal is that for every classifier that there is such a file for every classifier that is being used in the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe with the best parameters is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter name</th>\n",
       "      <th>parameter value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_estimators</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_samples</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>contamination</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>max_features</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parameter name parameter value\n",
       "0   n_estimators             550\n",
       "1    max_samples             1.0\n",
       "2  contamination             0.2\n",
       "3   max_features            0.45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split he list according to the comma and space characters that separate the params (', ')\n",
    "best_params_list = best_parameters_fine_search.split(', ')\n",
    "\n",
    "best_params_list = [best_params_list[0]] + [p for p in best_params_list[1:]]\n",
    "\n",
    "# put them to a dataframe\n",
    "best_params_df = pd.DataFrame({'parameter name': param_names_IF,\n",
    "                               'parameter value': best_params_list})\n",
    "\n",
    "print(\"The dataframe with the best parameters is:\\n\")\n",
    "display(best_params_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a csv using the name of the classifier as the file name\n",
    "best_params_df.to_csv(target_path_rel + 'Optimal Parameters --- {} (AUC).csv'\n",
    "                      .format(selected_classifier_name), \n",
    "                      index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the score and std of the best params\n",
    "fd = open(target_path_rel + 'Optimal Parameters --- {} (AUC).csv'.format(selected_classifier_name),'a')\n",
    "fd.write('--------------------------------------------------------------------------------\\n')\n",
    "fd.write('--------------------------------------------------------------------------------\\n')\n",
    "fd.write('The mean AUC rate across features and users of the above parameters is {:.4f}\\n'\n",
    "         .format(best_mean_of_AUC_fine_search))\n",
    "fd.write('The std of the aforementioned score is {:.4f}\\n'.format(std_of_AUC_mean_fine_search))\n",
    "fd.write('--------------------------------------------------------------------------------\\n')\n",
    "fd.write('The error for every separate case is measured in terms of its AUC score')\n",
    "fd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
